{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset.py","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPs3H1dlp1k5LmC7IdcQGd1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from pathlib import Path\n","import torch\n","import numpy as np \n","import imgaug \n","import imgaug.augmenters \n","from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n","import glob\n","import os\n","\n","class CardiacDataset(torch.utils.data.Dataset):\n","    def __init__(self, root, augment_params): #root directory\n","        self.all_files = self.extract_files(root)\n","        self.augment_params = augment_params\n","\n","    @staticmethod\n","    def extract_files(root):\n","        #Extract the paths to all slices given the root path (ends with train or val)\n","        files = []\n","        for subject in root.glob(\"*\"):\n","            slice_path = subject/\"data\"  # Get the slices for current subject,\n","            for slice in slice_path.glob(\"*.npy\"):\n","                files.append(slice)\n","        return files\n","\n","    @staticmethod\n","    def change_img_to_label_path(path):\n","        parts = list(path.parts)\n","        parts[parts.index(\"data\")] = \"masks\"\n","        return Path(\"*parts\")\n","\n","    def augment(self, slice, mask):\n","        # Fix for https://discuss.pytorch.org/t/dataloader-workers-generate-the-same-random-augmentations/28830/2,\n","        random_seed = torch.randint(0, 1000000, (1,)).item()\n","        imgaug.seed(random_seed)\n","        mask = SegmentationMapsOnImage(mask, mask.shape)\n","        slice_aug, mask_aug = self.augment_params(image=slice, segmentation_maps=mask)\n","        mask_aug = mask_aug.get_arr()\n","        return slice_aug, mask_aug\n","\n","    def __len__(self):\n","        #Return the length of the dataset (length of all files)\n","        return len(self.all_files)\n","\n","    def __getitem__(self, idx):\n","        print(self.all_files)\n","        file_path = self.all_files[idx]\n","        mask_path = self.change_img_to_label_path(file_path)\n","        slice = np.load(file_path).astype(np.float32)  # Convert to float for torch,\n","        mask = np.load(mask_path)\n","        if self.augment_params:\n","          slice, mask = self.augment(slice, mask)\n","      # Note that pytorch expects the input of shape BxCxHxW, where B corresponds to the batch size, C to the channels, H to the height and W to Width.,\n","      # As our data is of shape (HxW) we need to manually add the C axis by using expand_dims.,\n","        return np.expand_dims(slice, 0), np.expand_dims(mask, 0)\n","\n","\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZPsv-kxje7k","executionInfo":{"status":"ok","timestamp":1659292966138,"user_tz":-120,"elapsed":1927,"user":{"displayName":"Fennie van der Graaf","userId":"13308186546935518868"}},"outputId":"b7105aa1-6902-477b-f667-7765c076cbee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}