{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOSSK83oKNPZb1Mwa/Ifo+y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JzRr-x5Vq0jF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661607469365,"user_tz":-120,"elapsed":30626,"user":{"displayName":"Fennie van der Graaf","userId":"13308186546935518868"}},"outputId":"af58fbf8-0c60-42cb-c90a-e9ff4eb2ae06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install imgaug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpsI84Q04FYU","executionInfo":{"status":"ok","timestamp":1661607506040,"user_tz":-120,"elapsed":4873,"user":{"displayName":"Fennie van der Graaf","userId":"13308186546935518868"}},"outputId":"9b995069-21b4-4d2c-9a22-eff0ec42fa30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.4)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.9.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.6.0.66)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","import torch\n","import numpy as np \n","import imgaug \n","import imgaug.augmenters \n","from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n","import glob\n","import os"],"metadata":{"id":"o488aliHCPQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CardiacDataset(torch.utils.data.Dataset):\n","    def __init__(self, root, augment_params): #root directory\n","        self.all_files = self.extract_files(root)\n","        self.augment_params = augment_params\n","\n","    @staticmethod\n","    def extract_files(root):\n","        #Extract the paths to all slices given the root path (ends with train or val)\n","        files = []\n","        for subject in root.glob(\"*\"):\n","            slice_path = subject/\"data\"  # Get the slices for current subject,\n","            for slice in slice_path.glob(\"*.npy\"):\n","                files.append(slice)\n","        return files\n","\n","    @staticmethod\n","    def change_img_to_label_path(path):\n","        parts = list(path.parts)\n","        parts[parts.index(\"data\")] = \"masks\"\n","        return Path(\"*parts\")\n","\n","    def augment(self, slice, mask):\n","        # Fix for https://discuss.pytorch.org/t/dataloader-workers-generate-the-same-random-augmentations/28830/2,\n","        random_seed = torch.randint(0, 1000000, (1,)).item()\n","        imgaug.seed(random_seed)\n","        mask = SegmentationMapsOnImage(mask, mask.shape)\n","        slice_aug, mask_aug = self.augment_params(image=slice, segmentation_maps=mask)\n","        mask_aug = mask_aug.get_arr()\n","        return slice_aug, mask_aug\n","\n","    def __len__(self):\n","        #Return the length of the dataset (length of all files)\n","        return len(self.all_files)\n","\n","    def __getitem__(self, idx):\n","        print(self.all_files)\n","        file_path = self.all_files[idx]\n","        mask_path = self.change_img_to_label_path(file_path)\n","        slice = np.load(file_path).astype(np.float32)  # Convert to float for torch,\n","        mask = np.load(mask_path)\n","        if self.augment_params:\n","          slice, mask = self.augment(slice, mask)\n","      # Note that pytorch expects the input of shape BxCxHxW, where B corresponds to the batch size, C to the channels, H to the height and W to Width.,\n","      # As our data is of shape (HxW) we need to manually add the C axis by using expand_dims.,\n","        return np.expand_dims(slice, 0), np.expand_dims(mask, 0)\n","\n","\n","  "],"metadata":{"id":"jFGAYjuXDu9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import imgaug.augmenters as iaa\n","\n","seq = iaa.Sequential([\n","iaa.Affine(scale=(0.85, 1.15), # Zoom in or out,\n","rotate=(-45, 45)),  # Rotate up to 45 degrees,\n","iaa.ElasticTransformation()])  # Random Elastic Deformations,\n","\n","# Create the dataset object\n","path = \"/content/drive/My Drive/pytorch_udemy/06-Atrium-Segmentation/Preprocessed/\"\n","dataset = CardiacDataset(path, seq)\n","fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n","for i in range(3):\n","    for j in range(3):\n","        slice, mask = dataset[3]\n","        mask_ = np.ma.masked_where(mask==0, mask) #mask all pixels that are 0 in segmentation mask\n","        axis[i][j].imshow(slice[0], cmap='bone')\n","        axis[i][j].imshow(mask_[0], cmap='autumn')\n","        axis[i][j].axis('off')"],"metadata":{"id":"zbBLI_4EMLBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig.suptitle(Sample augmentations)\n","    plt.tight_layout()\n","   cell_type: markdown,\n","   id: victorian-affair,\n","   metadata: {},\n","   source: [\n","    Nice!,\n","    With above dataset we can finally create the model and train the AtriumSegmenter\n","   ]\n","  }\n"," ],\n"," metadata: {\n","  kernelspec: {\n","   display_name: Python 3 (ipykernel),\n","   language: python,\n","   name: python3\n","  },\n","  language_info: {\n","   codemirror_mode: {\n","    name: ipython,\n","    version: 3\n","   },\n","   file_extension: .py,\n","   mimetype: text/x-python,\n","   name: python,\n","   nbconvert_exporter: python,\n","   pygments_lexer: ipython3,\n","   version: 3.8.0\n","  }\n"," },\n"," nbformat: 4,\n"," nbformat_minor: 5\n","}\n"],"metadata":{"id":"LngLgdqh3vZf"},"execution_count":null,"outputs":[]}]}