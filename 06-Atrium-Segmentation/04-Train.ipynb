{"cells":[{"cell_type":"markdown","id":"corresponding-replication","metadata":{"id":"corresponding-replication"},"source":["## Introduction\n","Finally we are going to train our atrium segmentation network"]},{"cell_type":"markdown","id":"sacred-bahamas","metadata":{"id":"sacred-bahamas"},"source":["## Imports:\n","\n","* pathlib for easy path handling\n","* torch for tensor handling\n","* pytorch lightning for efficient and easy training implementation\n","* ModelCheckpoint and TensorboardLogger for checkpoint saving and logging\n","* imgaug for Data Augmentation\n","* numpy for file loading and array ops\n","* matplotlib for visualizing some images\n","* Our dataset and model\n","\n"]},{"cell_type":"code","execution_count":null,"id":"pregnant-density","metadata":{"id":"pregnant-density"},"outputs":[],"source":["from pathlib import Path\n","\n","import torch\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.loggers import TensorBoardLogger\n","import imgaug.augmenters as iaa\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from dataset import CardiacDataset\n","from model import UNet"]},{"cell_type":"markdown","id":"brutal-implementation","metadata":{"id":"brutal-implementation"},"source":["## Dataset Creation\n","Here we create the train and validation dataset. <br />\n","Additionally, we define our data augmentation pipeline.\n","Subsequently the two dataloaders are created"]},{"cell_type":"code","execution_count":null,"id":"broadband-arcade","metadata":{"id":"broadband-arcade"},"outputs":[],"source":["seq = iaa.Sequential([\n","    iaa.Affine(scale=(0.85, 1.15),\n","              rotate=(-45, 45)),\n","    iaa.ElasticTransformation()\n","])"]},{"cell_type":"code","execution_count":null,"id":"laughing-rehabilitation","metadata":{"id":"laughing-rehabilitation"},"outputs":[],"source":["# Create the dataset objects\n","train_path = Path(\"Preprocessed/train/\")\n","val_path = Path(\"Preprocessed/val\")\n","\n","train_dataset = CardiacDataset(train_path, seq)\n","val_dataset = CardiacDataset(val_path, None)\n","\n","print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")"]},{"cell_type":"code","execution_count":null,"id":"final-assets","metadata":{"id":"final-assets"},"outputs":[],"source":["batch_size = 8\n","num_workers = 4\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n"]},{"cell_type":"markdown","id":"mechanical-startup","metadata":{"id":"mechanical-startup"},"source":["## Custom Loss\n","Often segmentation models perform better when using a Dice Loss instead of Cross-Entropy.<br />\n","The Dice Loss is defined as:\n","$$ L(\\hat{y}, y) = 1-\\frac{2 |\\hat{y} \\cap y|}{|\\hat{y}| + |y|}$$\n","\n","The intersection can be easily computed by $\\hat{y}$ * $y$ as both variables are binary masks.\n","\n","You can read more about the Dice Score here:\n","https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient"]},{"cell_type":"code","execution_count":null,"id":"incorporate-horse","metadata":{"id":"incorporate-horse"},"outputs":[],"source":["class DiceLoss(torch.nn.Module):\n","    \"\"\"\n","    class to compute the Dice Loss\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, pred, mask):\n","                \n","        # Flatten label and prediction tensors\n","        pred = torch.flatten(pred)\n","        mask = torch.flatten(mask)\n","        counter = (pred * mask).sum()  # Numerator       \n","        denum = pred.sum() + mask.sum() + 1e-8  # Denominator. Add a small number to prevent NANS\n","        dice =  (2*counter)/denum\n","        return 1 - dice\n"]},{"cell_type":"markdown","id":"prime-radio","metadata":{"id":"prime-radio"},"source":["## Full Segmentation Model\n","\n","We will now combine everything into the full pytorch lightning model"]},{"cell_type":"code","execution_count":null,"id":"little-dover","metadata":{"id":"little-dover"},"outputs":[],"source":["class AtriumSegmentation(pl.LightningModule):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.model = UNet()\n","        \n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n","        self.loss_fn = DiceLoss()\n","        \n","    def forward(self, data):\n","        return torch.sigmoid(self.model(data))\n","    \n","    def training_step(self, batch, batch_idx):\n","        mri, mask = batch\n","        mask = mask.float()\n","        pred = self(mri)\n","        \n","        loss = self.loss_fn(pred, mask)\n","        \n","        self.log(\"Train Dice\", loss)\n","        \n","        if batch_idx % 50 == 0:\n","            self.log_images(mri.cpu(), pred.cpu(), mask.cpu(), \"Train\")\n","            \n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        mri, mask = batch\n","        mask = mask.float()\n","        pred = self(mri)\n","        \n","        loss = self.loss_fn(pred, mask)\n","        \n","        self.log(\"Val Dice\", loss)\n","        \n","        if batch_idx % 2 == 0:\n","            self.log_images(mri.cpu(), pred.cpu(), mask.cpu(), \"Val\")\n","            \n","        return loss\n","    \n","    def log_images(self, mri, pred, mask, name):\n","        \n","        pred = pred > 0.5\n","        \n","        fig, axis = plt.subplots(1, 2)\n","        axis[0].imshow(mri[0][0], cmap=\"bone\")\n","        mask_ = np.ma.masked_where(mask[0][0] == 0, mask[0][0])\n","        axis[0].imshow(mask_, alpha=0.6)\n","        \n","        axis[1].imshow(mri[0][0], cmap=\"bone\")\n","        mask_ = np.ma.masked_where(pred[0][0] == 0, pred[0][0])\n","        axis[1].imshow(mask_, alpha=0.6)\n","        \n","        self.logger.experiment.add_figure(name, fig, self.global_step)\n","        \n","    def configure_optimizers(self):\n","        return [self.optimizer]"]},{"cell_type":"code","execution_count":null,"id":"featured-nature","metadata":{"id":"featured-nature"},"outputs":[],"source":["# Instanciate the model and set the random seed\n","torch.manual_seed(0)\n","model = AtriumSegmentation()"]},{"cell_type":"code","execution_count":null,"id":"diagnostic-particle","metadata":{"id":"diagnostic-particle"},"outputs":[],"source":["# Create the checkpoint callback\n","checkpoint_callback = ModelCheckpoint(\n","    monitor='Val Dice',\n","    save_top_k=10,\n","    mode='min')"]},{"cell_type":"code","execution_count":null,"id":"pacific-inventory","metadata":{"id":"pacific-inventory"},"outputs":[],"source":["# Create the trainer\n","# Change the gpus parameter to the number of available gpus in your computer. Use 0 for CPU training\n","\n","gpus = 1 #TODO\n","trainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(save_dir=\"./logs\"), log_every_n_steps=1,\n","                     callbacks=checkpoint_callback,max_epochs=75)\n"]},{"cell_type":"code","execution_count":null,"id":"handy-testing","metadata":{"scrolled":false,"id":"handy-testing"},"outputs":[],"source":["trainer.fit(model, train_loader, val_loader)"]},{"cell_type":"markdown","id":"illegal-harvest","metadata":{"id":"illegal-harvest"},"source":["## Evaluation:\n","Let's evaluate the model\n","\n","* nibabel to load a full scan\n","* tqdm for progress bar when validating the model\n","* celluloid for easy video generation\n"]},{"cell_type":"code","execution_count":null,"id":"affecting-consolidation","metadata":{"id":"affecting-consolidation"},"outputs":[],"source":["import nibabel as nib\n","from tqdm.notebook import tqdm\n","from celluloid import Camera\n"]},{"cell_type":"markdown","id":"junior-tennis","metadata":{"id":"junior-tennis"},"source":["First we load a checkpoint:"]},{"cell_type":"code","execution_count":null,"id":"unavailable-medline","metadata":{"id":"unavailable-medline"},"outputs":[],"source":["model = AtriumSegmentation.load_from_checkpoint(\"weights/70.ckpt\")"]},{"cell_type":"code","execution_count":null,"id":"initial-strain","metadata":{"scrolled":true,"id":"initial-strain"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.eval();\n","model.to(device);"]},{"cell_type":"markdown","id":"every-injection","metadata":{"id":"every-injection"},"source":["Evalute the complete validation dataset"]},{"cell_type":"code","execution_count":null,"id":"imported-neighborhood","metadata":{"scrolled":true,"id":"imported-neighborhood"},"outputs":[],"source":["preds = []\n","labels = []\n","\n","for slice, label in tqdm(val_dataset):\n","    slice = torch.tensor(slice).to(device).unsqueeze(0)\n","    with torch.no_grad():\n","        pred = model(slice)\n","    preds.append(pred.cpu().numpy())\n","    labels.append(label)\n","    \n","preds = np.array(preds)\n","labels = np.array(labels)"]},{"cell_type":"markdown","id":"destroyed-hometown","metadata":{"id":"destroyed-hometown"},"source":["Compute overall Dice Score (1- DiceLoss):\n","Wow! What a great score"]},{"cell_type":"code","execution_count":null,"id":"sudden-password","metadata":{"id":"sudden-password"},"outputs":[],"source":["1-model.loss_fn(torch.from_numpy(preds), torch.from_numpy(labels))  # two possibilities"]},{"cell_type":"code","execution_count":null,"id":"weekly-issue","metadata":{"id":"weekly-issue"},"outputs":[],"source":["dice_score = 1-DiceLoss()(torch.from_numpy(preds), torch.from_numpy(labels).unsqueeze(0).float())\n","print(f\"The Val Dice Score is: {dice_score}\")"]},{"cell_type":"markdown","id":"dense-extent","metadata":{"id":"dense-extent"},"source":["## Visualization"]},{"cell_type":"markdown","id":"typical-batman","metadata":{"id":"typical-batman"},"source":["We can now load a test subject from the dataset and estimate the position of the left atrium"]},{"cell_type":"code","execution_count":null,"id":"prime-regard","metadata":{"id":"prime-regard"},"outputs":[],"source":["subject = Path(\"Task02_Heart/imagesTs/la_002.nii.gz\")\n","subject_mri = nib.load(subject).get_fdata()"]},{"cell_type":"markdown","id":"present-symphony","metadata":{"id":"present-symphony"},"source":["As this scan is neither normalized nor standardized we need to perform those tasks!<br />\n","Let us copy the normalization and standardization functions from our preprocessing notebook:"]},{"cell_type":"code","execution_count":null,"id":"frequent-indonesian","metadata":{"id":"frequent-indonesian"},"outputs":[],"source":["# Helper functions for normalization and standardization\n","def normalize(full_volume):\n","    \"\"\"\n","    Z-Normalization of the whole subject\n","    \"\"\"\n","    mu = full_volume.mean()\n","    std = np.std(full_volume)\n","    normalized = (full_volume - mu) / std\n","    return normalized\n","\n","def standardize(normalized_data):\n","    \"\"\"\n","    Standardize the normalized data into the 0-1 range\n","    \"\"\"\n","    standardized_data = (normalized_data - normalized_data.min()) / (normalized_data.max() - normalized_data.min())\n","    return standardized_data\n"]},{"cell_type":"markdown","id":"later-medicine","metadata":{"id":"later-medicine"},"source":["We preprocess the scan and crop 32 px from top, bottom, back and front"]},{"cell_type":"code","execution_count":null,"id":"defensive-coral","metadata":{"id":"defensive-coral"},"outputs":[],"source":["subject_mri = subject_mri[32:-32, 32:-32]\n","standardized_scan = standardize(normalize(subject_mri))"]},{"cell_type":"code","execution_count":null,"id":"enormous-clearing","metadata":{"id":"enormous-clearing"},"outputs":[],"source":["standardized_scan.shape"]},{"cell_type":"code","execution_count":null,"id":"civilian-lebanon","metadata":{"id":"civilian-lebanon"},"outputs":[],"source":["preds = []\n","for i in range(standardized_scan.shape[-1]):\n","    slice = standardized_scan[:,:,i]\n","    with torch.no_grad():\n","        pred = model(torch.tensor(slice).unsqueeze(0).unsqueeze(0).float().to(device))[0][0]\n","        pred = pred > 0.5\n","    preds.append(pred.cpu())"]},{"cell_type":"code","execution_count":null,"id":"minute-student","metadata":{"id":"minute-student"},"outputs":[],"source":["fig = plt.figure()\n","camera = Camera(fig)  # create the camera object from celluloid\n","\n","for i in range(standardized_scan.shape[-1]):\n","    plt.imshow(standardized_scan[:,:,i], cmap=\"bone\")\n","    mask = np.ma.masked_where(preds[i]==0, preds[i])\n","    plt.imshow(mask, alpha=0.5, cmap=\"autumn\")\n","    \n","    camera.snap()  # Store the current slice\n","animation = camera.animate()  # create the animation\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"falling-legislature","metadata":{"id":"falling-legislature"},"outputs":[],"source":["from IPython.display import HTML\n","HTML(animation.to_html5_video())  # convert the animation to a video\n"]},{"cell_type":"markdown","id":"supposed-function","metadata":{"id":"supposed-function"},"source":["Congratulations! You made it to the end of the segmentation lecture"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"name":"04-Train.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}