{"cells":[{"cell_type":"markdown","id":"universal-cartridge","metadata":{"id":"universal-cartridge"},"source":["## Introduction\n","In this notebook we will create the 3D-model for the liver and liver tumor segmentation! <br />"]},{"cell_type":"markdown","id":"alive-literacy","metadata":{"id":"alive-literacy"},"source":["## Imports:\n","1. torch for model creation"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ncxC5_1R-fT","executionInfo":{"status":"ok","timestamp":1662408760553,"user_tz":-120,"elapsed":35160,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}},"outputId":"ca9748e5-a9e0-4b0b-83b0-96349e8f34d9"},"id":"0ncxC5_1R-fT","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"nearby-offering","metadata":{"id":"nearby-offering","executionInfo":{"status":"ok","timestamp":1662408936094,"user_tz":-120,"elapsed":3030,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","id":"sexual-digest","metadata":{"id":"sexual-digest"},"source":["## Model Definition\n","We can use our previously defined 2D-UNET architecture with some small changes:\n","\n","1. Conv2d -> Conv3d\n","2. MaxPool2d -> MaxPool3d\n","3. \"trilinear\" upsampling method\n","4. Three Output Channels instead of One to model background, liver and tumor\n","\n","Additionally we drastically reduce the filters used in the convolutions to shrinken the network size"]},{"cell_type":"code","execution_count":3,"id":"changing-printer","metadata":{"id":"changing-printer","executionInfo":{"status":"ok","timestamp":1662408936395,"user_tz":-120,"elapsed":2,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["class DoubleConv(torch.nn.Module):\n","    \"\"\"\n","    Helper Class which implements the intermediate Convolutions\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        \n","        super().__init__()\n","        self.step = torch.nn.Sequential(torch.nn.Conv3d(in_channels, out_channels, 3, padding=1),\n","                                        torch.nn.ReLU(),\n","                                        torch.nn.Conv3d(out_channels, out_channels, 3, padding=1),\n","                                        torch.nn.ReLU())\n","        \n","    def forward(self, X):\n","        return self.step(X)\n"]},{"cell_type":"code","execution_count":4,"id":"twelve-boards","metadata":{"id":"twelve-boards","executionInfo":{"status":"ok","timestamp":1662408938411,"user_tz":-120,"elapsed":220,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["\n","class UNet(torch.nn.Module):\n","    \"\"\"\n","    This class implements a UNet for the Segmentation\n","    We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Sets up the U-Net Structure\n","        \"\"\"\n","        super().__init__()\n","        \n","        \n","        ############# DOWN #####################\n","        self.layer1 = DoubleConv(1, 32)\n","        self.layer2 = DoubleConv(32, 64)\n","        self.layer3 = DoubleConv(64, 128)\n","        self.layer4 = DoubleConv(128, 256)\n","\n","        #########################################\n","\n","        ############## UP #######################\n","        self.layer5 = DoubleConv(256 + 128, 128)\n","        self.layer6 = DoubleConv(128+64, 64)\n","        self.layer7 = DoubleConv(64+32, 32)\n","        self.layer8 = torch.nn.Conv3d(32, 3, 1)  # Output: 3 values -> background, liver, tumor\n","        #########################################\n","\n","        self.maxpool = torch.nn.MaxPool3d(2)\n","\n","    def forward(self, x):\n","        \n","        ####### DownConv 1#########\n","        x1 = self.layer1(x)\n","        x1m = self.maxpool(x1)\n","        ###########################\n","        \n","        ####### DownConv 2#########        \n","        x2 = self.layer2(x1m)\n","        x2m = self.maxpool(x2)\n","        ###########################\n","\n","        ####### DownConv 3#########        \n","        x3 = self.layer3(x2m)\n","        x3m = self.maxpool(x3)\n","        ###########################\n","        \n","        ##### Intermediate Layer ## \n","        x4 = self.layer4(x3m)\n","        ###########################\n","\n","        ####### UpCONV 1#########        \n","        x5 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x4)  # Upsample with a factor of 2\n","        x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n","        x5 = self.layer5(x5)\n","        ###########################\n","\n","        ####### UpCONV 2#########        \n","        x6 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x5)        \n","        x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection    \n","        x6 = self.layer6(x6)\n","        ###########################\n","        \n","        ####### UpCONV 3#########        \n","        x7 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x6)\n","        x7 = torch.cat([x7, x1], dim=1)       \n","        x7 = self.layer7(x7)\n","        ###########################\n","        \n","        ####### Predicted segmentation#########        \n","        ret = self.layer8(x7)\n","        return ret"]},{"cell_type":"markdown","id":"religious-pocket","metadata":{"id":"religious-pocket"},"source":["## Testing"]},{"cell_type":"code","execution_count":5,"id":"ignored-decimal","metadata":{"id":"ignored-decimal","executionInfo":{"status":"ok","timestamp":1662408941716,"user_tz":-120,"elapsed":202,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["model = UNet()"]},{"cell_type":"code","execution_count":6,"id":"stunning-season","metadata":{"id":"stunning-season","executionInfo":{"status":"ok","timestamp":1662408943093,"user_tz":-120,"elapsed":209,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["random_input = torch.randn(1, 1, 128, 128, 128)\n"]},{"cell_type":"code","execution_count":7,"id":"nonprofit-adams","metadata":{"scrolled":false,"id":"nonprofit-adams","executionInfo":{"status":"ok","timestamp":1662408965502,"user_tz":-120,"elapsed":20982,"user":{"displayName":"Fennie Easton","userId":"16256458271197189251"}}},"outputs":[],"source":["with torch.no_grad():\n","    output = model(random_input)\n","assert output.shape == torch.Size([1, 3, 128, 128, 128])"]},{"cell_type":"code","source":[],"metadata":{"id":"lYQYYyyxS2hy"},"id":"lYQYYyyxS2hy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}